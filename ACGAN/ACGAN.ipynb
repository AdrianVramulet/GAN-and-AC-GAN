{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031680be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64e89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc88d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf0e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim + num_classes,)),\n",
    "        \n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "def make_discriminator():\n",
    "    image_in = keras.Input(shape=(28, 28, 1))\n",
    "    \n",
    "    conv1 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\")\n",
    "    c1 = conv1(image_in)\n",
    "    relu1 = layers.LeakyReLU(alpha=0.2)\n",
    "    r1 = relu1(c1)\n",
    "    conv2 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\")\n",
    "    c2 = conv2(r1)\n",
    "    relu2 = layers.LeakyReLU(alpha=0.2)\n",
    "    r2 = relu2(c2)\n",
    "    \n",
    "    flatten = layers.Flatten()\n",
    "    f = flatten(r2)\n",
    "    \n",
    "    #output real fake\n",
    "    dense = layers.Dense(1)\n",
    "    output_realfake = dense(f)\n",
    "    \n",
    "    #output digit label\n",
    "    dense128 = layers.Dense(128)\n",
    "    d2 = dense128(f)\n",
    "    dense10 = layers.Dense(num_classes, activation=\"softmax\")\n",
    "    labels = dense10(d2)\n",
    "    \n",
    "    model = keras.Model(inputs=image_in, outputs=[output_realfake, labels], name=\"discriminator\")\n",
    "    \n",
    "    return model\n",
    "discriminator = make_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a11156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "    \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        #if isinstance(real_images, tuple):\n",
    "        #    real_images = real_images[0]\n",
    "        \n",
    "        real_images = data[0]\n",
    "        real_labels = data[1]        \n",
    "        \n",
    "            \n",
    "        # Sample random points in the latent space\n",
    "        batch_size = real_images.shape[0]\n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        #random_labels = tf.random.uniform(shape=(batch_size,), minval=0, maxval=10, dtype=tf.int32)\n",
    "        #random_labels = tf.keras.utils.to_categorical(random_labels, num_classes=10, dtype=tf.int32)\n",
    "        random_labels = real_labels\n",
    "        \n",
    "        gen_input_vectors = tf.concat([random_latent_vectors, random_labels], axis=1)\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(gen_input_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images; 1 = fake, 0 = real\n",
    "        realfakelabels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        \n",
    "        digitlabels = tf.concat([random_labels, real_labels], axis=0)\n",
    "        \n",
    "        \n",
    "        # Add random noise to the labels - important trick!\n",
    "        realfakelabels += 0.05 * tf.random.uniform(tf.shape(realfakelabels))\n",
    "        \n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            realfakepred, labelpred = self.discriminator(combined_images)\n",
    "            d_rf_loss = self.loss_fn[0](realfakelabels, realfakepred)\n",
    "            d_label_loss = self.loss_fn[1](digitlabels, labelpred)\n",
    "        grads = tape.gradient([d_rf_loss, d_label_loss], self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        #random_labels = tf.random.uniform(shape=(batch_size,), minval=0, maxval=10, dtype=tf.int32)\n",
    "        #random_labels = tf.keras.utils.to_categorical(random_labels, num_classes=10, dtype='int32')\n",
    "        random_labels = real_labels\n",
    "        \n",
    "        gen_input_vectors = tf.concat([random_latent_vectors, random_labels], axis=1)\n",
    "\n",
    "        \n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_realfake = tf.zeros((batch_size, 1))\n",
    "    \n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            realfakepred, labelpred = self.discriminator(self.generator(gen_input_vectors))\n",
    "            g_rf_loss = self.loss_fn[0](misleading_realfake, realfakepred)\n",
    "            g_label_loss = self.loss_fn[1](random_labels, labelpred)\n",
    "        grads = tape.gradient([g_rf_loss, g_label_loss], self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        return {\"d_loss\": (d_rf_loss + d_label_loss), \"g_loss\": (g_rf_loss + g_label_loss)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7da306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = GAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=[\n",
    "        keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "        keras.losses.CategoricalCrossentropy()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8781213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 107s 199ms/step - d_loss: 1.4707 - g_loss: 8.4757\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 1.4598 - g_loss: 17.4436\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.9246 - g_loss: 1.7340 ETA: 0s - d_loss: 0.9251 - g_loss: \n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7857 - g_loss: 1.1424\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7067 - g_loss: 1.1309\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6906 - g_loss: 1.3107\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7794 - g_loss: 1.0634\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7486 - g_loss: 0.9224\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7573 - g_loss: 0.9554\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7515 - g_loss: 0.8645 - d_loss: 0.7516 - g_loss\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7508 - g_loss: 0.887630s - d_loss:\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7247 - g_loss: 0.8920\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7405 - g_loss: 0.8653\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7271 - g_loss: 0.839953s - d_loss: 0.7 - ETA: 49s - d_l\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7310 - g_loss: 0.8690 - d_loss: 0.7308 - g_\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7217 - g_loss: 0.842823s - ETA: 4s - d_loss: 0.7 - ETA: 2s - d_los\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7129 - g_loss: 0.8764\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7077 - g_loss: 0.8672 -\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7101 - g_loss: 0.8672 - d_loss: 0.7\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6930 - g_loss: 0.8567\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7017 - g_loss: 0.8751\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6983 - g_loss: 0.8692: 48s - d_los\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6972 - g_loss: 0.860813s -\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6976 - g_loss: 0.849954s - d_loss: 0.6997  - E - ETA: 43s - d_loss: 0.7017 - g_loss: 0.843 -\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6974 - g_loss: 0.846656s - d_loss: 0.6914 - g_loss: 0 - ETA: 55s - d_los - ETA: 49s \n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7048 - g_loss: 0.8269\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7071 - g_loss: 0.829422s - d_loss: 0.7069 - g_loss: 0. - ETA: 21s -  - ETA:  - ETA: 0s - d_loss: 0.7069 - g_loss: 0.\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6972 - g_loss: 0.8248 ETA: 24s - - ETA: 0s - d_loss: 0.6971 - g_loss\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7019 - g_loss: 0.8331 - d_l\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6989 - g_loss: 0.8309\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6950 - g_loss: 0.8429 - d\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6945 - g_loss: 0.8236\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6965 - g_loss: 0.8212 - d_loss: 0\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6937 - g_loss: 0.8291: 2s - d_l\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6975 - g_loss: 0.8239\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6957 - g_loss: 0.8152\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6947 - g_loss: 0.8235\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6925 - g_loss: 0.813452s - d_l - ETA: 47s - d_l - ETA: 32s - d_loss: 0.690 - ETA: 29s - d_loss: 0 - ETA: 24s - d_loss: 0.6906 - g - ETA: 13s - d_loss: 0.6903 - g_los - ETA: - ETA: 2s - d_loss: 0 - ETA: 0s - d_loss: 0.6926 - g_loss: 0.\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6954 - g_loss: 0.8310\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6883 - g_loss: 0.8135\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6897 - g_loss: 0.8343\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6876 - g_loss: 0.822934s - - ETA: 28s - d_loss: 0.6869 - g\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6859 - g_loss: 0.8402\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6852 - g_loss: 0.8290\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6765 - g_loss: 0.8294\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6819 - g_loss: 0.8545 - ETA: 31s - d_loss: 0.6788 - g_loss: 0.8 - ETA: 21s - d_loss - ETA: 16s - d_loss: 0.6812 - g_loss - ETA: 15s - d_loss: 0.6815 - g_loss: 0.859 - ETA: 15s - d_loss: 0.68 - ETA: 11s - d_loss: 0.6814 - g_loss:  - ETA:  - ETA: 6s - d_loss: 0\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6780 - g_loss: 0.8265\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6760 - g_loss: 0.838713s - d_lo - ETA: 0s - d_loss: 0.6760 - g_loss: \n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6703 - g_loss: 0.8484 - d_loss: 0.6726 - g_loss:  - ETA: 4s - d_loss: - ETA: 2s - d_loss:\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6746 - g_loss: 0.82425s - d_loss: 0.6747 - g_loss: 0.82 - ETA: 4s - d_loss: 0.6747 -  - ETA: 3s - d_loss: 0 - ETA: 1s - d_loss: 0.6748 \n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6740 - g_loss: 0.8437\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6715 - g_loss: 0.8501\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6695 - g_loss: 0.8502\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6607 - g_loss: 0.8542\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6632 - g_loss: 0.8605 - d_loss: 0.6629 - \n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6648 - g_loss: 0.8288\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6625 - g_loss: 0.8501 - - ETA: 1s - d_loss: 0.6629 \n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6615 - g_loss: 0.8496 - d_loss: 0.661 - E\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6642 - g_loss: 0.8492\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6635 - g_loss: 0.8485\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6667 - g_loss: 0.8327\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6676 - g_loss: 0.8372\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6752 - g_loss: 0.829331s - d_loss: 0.6713  - ETA: 27s - d_loss: 0. - ETA: 14\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6731 - g_loss: 0.8164\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6756 - g_loss: 0.8284\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6781 - g_loss: 0.8073 - d_loss: 0.6787 - \n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6826 - g_loss: 0.8156 48s - d_loss: \n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6857 - g_loss: 0.802642s - d_loss: 0 - ET - ETA: 2s - d_loss:\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6835 - g_loss: 0.8024\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6882 - g_loss: 0.8032\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6917 - g_loss: 0.7908\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6911 - g_loss: 0.7945\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6919 - g_loss: 0.7891 - d_loss: 0.6923  - ETA: 1s - d_loss: 0.6920 - \n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6936 - g_loss: 0.7835\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6944 - g_loss: 0.7818\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6961 - g_loss: 0.7749\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6976 - g_loss: 0.7817\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6990 - g_loss: 0.7705\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6983 - g_loss: 0.770645s - d_loss: 0.6976 -  - ET\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7007 - g_loss: 0.7669\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7000 - g_loss: 0.764054s - d_loss: 0.69 -  -\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7004 - g_loss: 0.7658\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7020 - g_loss: 0.7588\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7025 - g_loss: 0.7588\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7010 - g_loss: 0.7619\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7015 - g_loss: 0.7560\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7020 - g_loss: 0.7626\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6995 - g_loss: 0.7601 - d_loss: 0.6997  - ETA: 1s - d_loss: 0.6995 \n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7004 - g_loss: 0.753948s - d_lo - ETA: 34s - d_loss: 0.7 - ETA: 30s - d_loss: 0.7002 - ETA: 17s - d_loss: 0.7003 - g_loss:\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6999 - g_loss: 0.7591TA: \n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6985 - g_loss: 0.7632\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6998 - g_loss: 0.7561 - d_loss: 0.700 - ETA: 1s - d_loss: 0.7002 - \n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6979 - g_loss: 0.7613\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6994 - g_loss: 0.7541\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6992 - g_loss: 0.75715\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.7000 - g_loss: 0.7548\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6995 - g_loss: 0.7596ETA: 1\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6982 - g_loss: 0.7540\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6982 - g_loss: 0.7554\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 100s 200ms/step - d_loss: 0.6980 - g_loss: 0.7605 - d_loss: 0.6979 - g_loss: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237ab4cf430>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cond_gan.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "cond_gan.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "#cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f24e5e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: generator\\assets\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: discriminator\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#cond_gan.save(\"GAN\")\n",
    "generator.save(\"generator\")\n",
    "discriminator.save(\"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d67bc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit(n = 0):\n",
    "    \n",
    "    noise = np.random.randn(latent_dim)\n",
    "    gen_input = tf.reshape(noise, (1, latent_dim))\n",
    "    gen_input = np.concatenate([gen_input, tf.reshape(np.eye(10)[n], (1, 10))], axis=1)\n",
    "    \n",
    "    image = generator.predict(gen_input)\n",
    "    image *= 256\n",
    "    image = image.astype(np.uint8)\n",
    "    image = image[0]\n",
    "    \n",
    "    fig = plt.figure\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return discriminator.predict(generator.predict(gen_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a8bb4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.13064066]], dtype=float32),\n",
       " array([[5.54356298e-14, 4.75499038e-26, 2.66139605e-16, 6.17236507e-18,\n",
       "         3.73538450e-10, 3.29490893e-16, 1.25472631e-22, 1.04990745e-08,\n",
       "         1.27579306e-12, 1.00000000e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_digit(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_good_digit(n = 0):\n",
    "    \n",
    "    \n",
    "    while 1>0:\n",
    "        noise = np.random.randn(latent_dim)\n",
    "        gen_input = tf.reshape(noise, (1, latent_dim))\n",
    "        image = generator.predict(gen_input)\n",
    "        if(discriminator.predict(image) < 0.1):\n",
    "            break\n",
    "    \n",
    "    image *= 256\n",
    "    image = image.astype(np.uint8)\n",
    "    image = image[0]\n",
    "    \n",
    "    fig = plt.figure\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return discriminator.predict(generator.predict(gen_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_good_digit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe739c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36647dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a301df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc195f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069dea71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7a4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429ae6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
